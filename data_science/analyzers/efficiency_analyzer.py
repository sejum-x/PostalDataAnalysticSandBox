# data_science/analyzers/efficiency_analyzer.py
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from datetime import datetime, timedelta
import sys

sys.path.append('..')
from data_science.base_model import BaseMLModel
from utils.helpers import get_latest_csv_file


class EfficiencyAnalyzer(BaseMLModel):
    """–ê–Ω–∞–ª—ñ–∑ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö"""

    def __init__(self):
        super().__init__("efficiency_analyzer")
        self.anomaly_detector = IsolationForest(contamination=0.1, random_state=42)

    def analyze_department_performance(self):
        """–ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –≤—ñ–¥–¥—ñ–ª–µ–Ω—å"""
        print("üè¢ –ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –≤—ñ–¥–¥—ñ–ª–µ–Ω—å...")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
        delivery_file = get_latest_csv_file(self.config.RAW_DATA_PATH, 'delivery_periodic_raw_data_*.csv')
        if not delivery_file:
            raise FileNotFoundError("–§–∞–π–ª delivery_periodic_raw_data –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")

        data = pd.read_csv(delivery_file)

        # –ê–Ω–∞–ª—ñ–∑ –ø–æ –≤—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è–º
        dept_analysis = data.groupby(
            ['department_id', 'department_number', 'department_city', 'department_region']).agg({
            'deliveries_count': ['sum', 'mean', 'std'],
            'processing_time_hours': ['mean', 'std'],
            'deliveries_share_percentage': 'mean',
            'start_month': 'count'  # –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä—ñ–æ–¥—ñ–≤ —Ä–æ–±–æ—Ç–∏
        }).round(2)

        # –°–ø—Ä–æ—â–µ–Ω–Ω—è –Ω–∞–∑–≤ –∫–æ–ª–æ–Ω–æ–∫
        dept_analysis.columns = [
            'total_deliveries', 'avg_deliveries_per_period', 'std_deliveries',
            'avg_processing_time', 'std_processing_time',
            'avg_market_share', 'active_periods'
        ]

        # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–µ—Ç—Ä–∏–∫ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        dept_analysis['deliveries_per_hour'] = (
                dept_analysis['avg_deliveries_per_period'] /
                (dept_analysis['avg_processing_time'] + 0.1)
        )

        dept_analysis['consistency_score'] = (
                1 / (dept_analysis['std_deliveries'] + 1)
        )

        dept_analysis['efficiency_score'] = (
                dept_analysis['deliveries_per_hour'] * 0.4 +
                dept_analysis['consistency_score'] * 0.3 +
                dept_analysis['avg_market_share'] * 0.3
        )

        # –í–∏—è–≤–ª–µ–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π
        features_for_anomaly = ['avg_deliveries_per_period', 'avg_processing_time', 'avg_market_share']
        X_anomaly = dept_analysis[features_for_anomaly].fillna(0)

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_anomaly)

        anomalies = self.anomaly_detector.fit_predict(X_scaled)
        dept_analysis['is_anomaly'] = anomalies == -1

        # –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –≤—ñ–¥–¥—ñ–ª–µ–Ω—å
        dept_analysis['performance_category'] = pd.cut(
            dept_analysis['efficiency_score'],
            bins=[-np.inf, dept_analysis['efficiency_score'].quantile(0.25),
                  dept_analysis['efficiency_score'].quantile(0.75), np.inf],
            labels=['Needs_Improvement', 'Average', 'High_Performance']
        )

        return dept_analysis.reset_index()

    def analyze_transport_efficiency(self):
        """–ê–Ω–∞–ª—ñ–∑ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É"""
        print("üöõ –ê–Ω–∞–ª—ñ–∑ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É...")

        delivery_file = get_latest_csv_file(self.config.RAW_DATA_PATH, 'delivery_periodic_raw_data_*.csv')
        data = pd.read_csv(delivery_file)

        # –ê–Ω–∞–ª—ñ–∑ –ø–æ —Ç–∏–ø–∞—Ö —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É
        transport_analysis = data.groupby(['transport_body_type_id', 'transport_type_name']).agg({
            'deliveries_count': ['sum', 'mean'],
            'processing_time_hours': 'mean',
            'parcel_max_weight': 'mean',
            'department_id': 'nunique'  # –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤—ñ–¥–¥—ñ–ª–µ–Ω—å, —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å
        }).round(2)

        transport_analysis.columns = [
            'total_deliveries', 'avg_deliveries_per_period',
            'avg_processing_time', 'avg_max_weight', 'departments_using'
        ]

        # –ú–µ—Ç—Ä–∏–∫–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É
        transport_analysis['weight_efficiency'] = (
                transport_analysis['avg_max_weight'] /
                (transport_analysis['avg_processing_time'] + 0.1)
        )

        transport_analysis['utilization_rate'] = (
                transport_analysis['departments_using'] /
                transport_analysis['departments_using'].max()
        )

        transport_analysis['transport_efficiency_score'] = (
                transport_analysis['weight_efficiency'] * 0.4 +
                transport_analysis['utilization_rate'] * 0.6
        )

        return transport_analysis.reset_index()

    def analyze_seasonal_patterns(self):
        """–ê–Ω–∞–ª—ñ–∑ —Å–µ–∑–æ–Ω–Ω–∏—Ö –ø–∞—Ç–µ—Ä–Ω—ñ–≤"""
        print("üìÖ –ê–Ω–∞–ª—ñ–∑ —Å–µ–∑–æ–Ω–Ω–∏—Ö –ø–∞—Ç–µ—Ä–Ω—ñ–≤...")

        delivery_file = get_latest_csv_file(self.config.RAW_DATA_PATH, 'delivery_periodic_raw_data_*.csv')
        data = pd.read_csv(delivery_file)

        # –ê–Ω–∞–ª—ñ–∑ –ø–æ –º—ñ—Å—è—Ü—è—Ö
        monthly_analysis = data.groupby('start_month').agg({
            'deliveries_count': ['sum', 'mean', 'std'],
            'processing_time_hours': 'mean',
            'department_id': 'nunique'
        }).round(2)

        monthly_analysis.columns = [
            'total_deliveries', 'avg_deliveries', 'std_deliveries',
            'avg_processing_time', 'active_departments'
        ]

        # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Å–µ–∑–æ–Ω—ñ–≤
        seasons = {
            'Winter': [12, 1, 2],
            'Spring': [3, 4, 5],
            'Summer': [6, 7, 8],
            'Autumn': [9, 10, 11]
        }

        seasonal_analysis = {}
        for season, months in seasons.items():
            season_data = data[data['start_month'].isin(months)]
            if len(season_data) > 0:
                seasonal_analysis[season] = {
                    'total_deliveries': season_data['deliveries_count'].sum(),
                    'avg_processing_time': season_data['processing_time_hours'].mean(),
                    'active_departments': season_data['department_id'].nunique(),
                    'months_included': months
                }

        return {
            'monthly_patterns': monthly_analysis.to_dict('index'),
            'seasonal_patterns': seasonal_analysis
        }

    def generate_improvement_recommendations(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è"""
        print("üí° –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è...")

        dept_analysis = self.analyze_department_performance()
        transport_analysis = self.analyze_transport_efficiency()
        seasonal_analysis = self.analyze_seasonal_patterns()

        recommendations = []

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –≤—ñ–¥–¥—ñ–ª–µ–Ω—å
        low_performance_depts = dept_analysis[
            dept_analysis['performance_category'] == 'Needs_Improvement'
            ]

        for _, dept in low_performance_depts.iterrows():
            recommendations.append({
                'type': 'department_improvement',
                'target': f"–í—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è {dept['department_number']} ({dept['department_city']})",
                'priority': 'high',
                'issues': [
                    f"–ù–∏–∑—å–∫–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å: {dept['efficiency_score']:.2f}",
                    f"–ß–∞—Å –æ–±—Ä–æ–±–∫–∏: {dept['avg_processing_time']:.1f} –≥–æ–¥",
                    f"–°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–æ—Å—Ç–∞–≤–æ–∫: {dept['avg_deliveries_per_period']:.1f}"
                ],
                'suggestions': [
                    '–û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ –ø—Ä–æ—Ü–µ—Å–∏ –æ–±—Ä–æ–±–∫–∏ –ø–æ—Å–∏–ª–æ–∫',
                    '–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ—Å—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª—É',
                    '–†–æ–∑–≥–ª—è–Ω—É—Ç–∏ –¥–æ–¥–∞—Ç–∫–æ–≤–µ –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—è'
                ]
            })

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –ø–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É
        transport_sorted = transport_analysis.sort_values('transport_efficiency_score')
        low_efficiency_transport = transport_sorted.head(3)

        for _, transport in low_efficiency_transport.iterrows():
            recommendations.append({
                'type': 'transport_optimization',
                'target': f"–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç: {transport['transport_type_name']}",
                'priority': 'medium',
                'issues': [
                    f"–ù–∏–∑—å–∫–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å: {transport['transport_efficiency_score']:.2f}",
                    f"–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –≤ {transport['departments_using']} –≤—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è—Ö"
                ],
                'suggestions': [
                    '–†–æ–∑–≥–ª—è–Ω—É—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ñ —Ç–∏–ø–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç—É',
                    '–û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ –º–∞—Ä—à—Ä—É—Ç–∏',
                    '–ó–±—ñ–ª—å—à–∏—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ —ñ–Ω—à–∏—Ö –≤—ñ–¥–¥—ñ–ª–µ–Ω–Ω—è—Ö'
                ]
            })

        # –°–µ–∑–æ–Ω–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        seasonal_patterns = seasonal_analysis['seasonal_patterns']
        if seasonal_patterns:
            peak_season = max(seasonal_patterns.items(),
                              key=lambda x: x[1]['total_deliveries'])

            recommendations.append({
                'type': 'seasonal_planning',
                'target': f"–°–µ–∑–æ–Ω–Ω–µ –ø–ª–∞–Ω—É–≤–∞–Ω–Ω—è",
                'priority': 'medium',
                'issues': [
                    f"–ü—ñ–∫ –¥–æ—Å—Ç–∞–≤–æ–∫ –≤ —Å–µ–∑–æ–Ω—ñ: {peak_season[0]}",
                    f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å: {peak_season[1]['total_deliveries']}"
                ],
                'suggestions': [
                    f'–ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Ä–µ—Å—É—Ä—Å–∏ –Ω–∞ {peak_season[0].lower()}',
                    '–ü–ª–∞–Ω—É–≤–∞—Ç–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª –∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å',
                    '–û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ —Å–∫–ª–∞–¥–∏ –ø–µ—Ä–µ–¥ –ø—ñ–∫–æ–≤–∏–º —Å–µ–∑–æ–Ω–æ–º'
                ]
            })

        return recommendations